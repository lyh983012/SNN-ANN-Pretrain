{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf4c593",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use torch.cuda.amp.autocast for fusion prcision training\n",
      "Total number of paramerters in networks is 11185379  \n",
      "===> training models...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lyh/anaconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448255797/work/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====> Epoch [0/60], Step [10/140], Loss: 20.57126 , Acc: 24.37500  \n",
      "=====> Epoch [0/60], Step [20/140], Loss: 17.76989 , Acc: 35.46875  \n",
      "=====> Epoch [0/60], Step [30/140], Loss: 17.02118 , Acc: 37.81250  \n",
      "=====> Epoch [0/60], Step [40/140], Loss: 16.27520 , Acc: 42.18750  \n",
      "=====> Epoch [0/60], Step [50/140], Loss: 15.58616 , Acc: 43.43750  \n",
      "=====> Epoch [0/60], Step [60/140], Loss: 14.84928 , Acc: 46.56250  \n",
      "=====> Epoch [0/60], Step [70/140], Loss: 14.32769 , Acc: 49.53125  \n",
      "=====> Epoch [0/60], Step [80/140], Loss: 14.51199 , Acc: 49.53125  \n",
      "=====> Epoch [0/60], Step [90/140], Loss: 14.74642 , Acc: 48.28125  \n",
      "=====> Epoch [0/60], Step [100/140], Loss: 13.50469 , Acc: 52.65625  \n",
      "=====> Epoch [0/60], Step [110/140], Loss: 14.25400 , Acc: 50.93750  \n",
      "=====> Epoch [0/60], Step [120/140], Loss: 12.71234 , Acc: 55.93750  \n",
      "=====> Epoch [0/60], Step [130/140], Loss: 12.85976 , Acc: 54.84375  \n",
      "=====> Epoch [0/60], Step [140/140], Loss: 13.59897 , Acc: 51.25000  \n",
      "===> evaluating models...\n",
      "================\n",
      "val acc: 12.708333333333334 %  epoch: 0\n",
      "================\n",
      "===> Saving models...\n",
      "===> training models...\n",
      "=====> Epoch [1/60], Step [10/140], Loss: 12.21319 , Acc: 57.03125  \n",
      "=====> Epoch [1/60], Step [20/140], Loss: 11.41299 , Acc: 63.12500  \n",
      "=====> Epoch [1/60], Step [30/140], Loss: 12.31966 , Acc: 57.50000  \n",
      "=====> Epoch [1/60], Step [40/140], Loss: 12.18774 , Acc: 57.18750  \n",
      "=====> Epoch [1/60], Step [50/140], Loss: 12.78187 , Acc: 55.15625  \n",
      "=====> Epoch [1/60], Step [60/140], Loss: 12.38891 , Acc: 57.50000  \n",
      "=====> Epoch [1/60], Step [70/140], Loss: 12.55280 , Acc: 56.56250  \n",
      "=====> Epoch [1/60], Step [80/140], Loss: 11.76211 , Acc: 60.46875  \n",
      "=====> Epoch [1/60], Step [90/140], Loss: 12.08575 , Acc: 58.59375  \n",
      "=====> Epoch [1/60], Step [100/140], Loss: 11.18606 , Acc: 60.93750  \n",
      "=====> Epoch [1/60], Step [110/140], Loss: 11.60263 , Acc: 60.00000  \n",
      "=====> Epoch [1/60], Step [120/140], Loss: 11.54896 , Acc: 61.71875  \n",
      "=====> Epoch [1/60], Step [130/140], Loss: 11.59137 , Acc: 56.71875  \n",
      "=====> Epoch [1/60], Step [140/140], Loss: 11.83262 , Acc: 59.21875  \n",
      "===> evaluating models...\n",
      "================\n",
      "val acc: 10.208333333333334 %  epoch: 1\n",
      "================\n",
      "===> training models...\n",
      "=====> Epoch [2/60], Step [10/140], Loss: 10.25372 , Acc: 61.87500  \n",
      "=====> Epoch [2/60], Step [20/140], Loss: 10.27887 , Acc: 63.75000  \n",
      "=====> Epoch [2/60], Step [30/140], Loss: 10.13826 , Acc: 63.90625  \n",
      "=====> Epoch [2/60], Step [40/140], Loss: 10.67761 , Acc: 64.37500  \n",
      "=====> Epoch [2/60], Step [50/140], Loss: 11.16488 , Acc: 63.28125  \n",
      "=====> Epoch [2/60], Step [60/140], Loss: 10.97876 , Acc: 60.93750  \n",
      "=====> Epoch [2/60], Step [70/140], Loss: 11.35001 , Acc: 58.12500  \n",
      "=====> Epoch [2/60], Step [80/140], Loss: 11.13307 , Acc: 62.34375  \n",
      "=====> Epoch [2/60], Step [90/140], Loss: 11.36539 , Acc: 61.09375  \n",
      "=====> Epoch [2/60], Step [100/140], Loss: 10.20395 , Acc: 66.56250  \n",
      "=====> Epoch [2/60], Step [110/140], Loss: 10.22982 , Acc: 64.84375  \n",
      "=====> Epoch [2/60], Step [120/140], Loss: 10.71198 , Acc: 63.75000  \n",
      "=====> Epoch [2/60], Step [130/140], Loss: 10.80474 , Acc: 63.12500  \n",
      "=====> Epoch [2/60], Step [140/140], Loss: 10.10680 , Acc: 65.15625  \n",
      "===> evaluating models...\n",
      "================\n",
      "val acc: 19.895833333333332 %  epoch: 2\n",
      "================\n",
      "===> Saving models...\n",
      "===> training models...\n",
      "=====> Epoch [3/60], Step [10/140], Loss: 9.31803 , Acc: 66.71875  \n",
      "=====> Epoch [3/60], Step [20/140], Loss: 10.03366 , Acc: 67.50000  \n",
      "=====> Epoch [3/60], Step [30/140], Loss: 9.84068 , Acc: 65.00000  \n",
      "=====> Epoch [3/60], Step [40/140], Loss: 9.92465 , Acc: 66.25000  \n",
      "=====> Epoch [3/60], Step [50/140], Loss: 9.34979 , Acc: 67.18750  \n",
      "=====> Epoch [3/60], Step [60/140], Loss: 10.32497 , Acc: 66.09375  \n",
      "=====> Epoch [3/60], Step [70/140], Loss: 9.69854 , Acc: 67.03125  \n",
      "=====> Epoch [3/60], Step [80/140], Loss: 8.78800 , Acc: 69.68750  \n",
      "=====> Epoch [3/60], Step [90/140], Loss: 9.84908 , Acc: 63.43750  \n",
      "=====> Epoch [3/60], Step [100/140], Loss: 10.20262 , Acc: 64.53125  \n",
      "=====> Epoch [3/60], Step [110/140], Loss: 10.29249 , Acc: 65.31250  \n",
      "=====> Epoch [3/60], Step [120/140], Loss: 9.21829 , Acc: 70.00000  \n",
      "=====> Epoch [3/60], Step [130/140], Loss: 9.52611 , Acc: 69.37500  \n",
      "=====> Epoch [3/60], Step [140/140], Loss: 10.77938 , Acc: 63.43750  \n",
      "===> evaluating models...\n",
      "================\n",
      "val acc: 20.104166666666668 %  epoch: 3\n",
      "================\n",
      "===> Saving models...\n",
      "===> training models...\n",
      "=====> Epoch [4/60], Step [10/140], Loss: 8.40162 , Acc: 71.25000  \n",
      "=====> Epoch [4/60], Step [20/140], Loss: 7.77693 , Acc: 73.12500  \n",
      "=====> Epoch [4/60], Step [30/140], Loss: 8.84063 , Acc: 70.31250  \n",
      "=====> Epoch [4/60], Step [40/140], Loss: 8.11209 , Acc: 72.50000  \n",
      "=====> Epoch [4/60], Step [50/140], Loss: 8.27139 , Acc: 71.25000  \n",
      "=====> Epoch [4/60], Step [60/140], Loss: 9.48179 , Acc: 68.28125  \n",
      "=====> Epoch [4/60], Step [70/140], Loss: 8.64967 , Acc: 72.18750  \n",
      "=====> Epoch [4/60], Step [80/140], Loss: 9.99895 , Acc: 68.28125  \n",
      "=====> Epoch [4/60], Step [90/140], Loss: 8.80164 , Acc: 69.84375  \n",
      "=====> Epoch [5/60], Step [60/140], Loss: 8.18885 , Acc: 72.50000  \n",
      "=====> Epoch [5/60], Step [70/140], Loss: 7.42347 , Acc: 75.46875  \n",
      "=====> Epoch [5/60], Step [80/140], Loss: 9.66875 , Acc: 67.03125  \n",
      "=====> Epoch [5/60], Step [90/140], Loss: 8.72518 , Acc: 69.84375  \n",
      "=====> Epoch [5/60], Step [100/140], Loss: 8.09783 , Acc: 72.18750  \n",
      "=====> Epoch [5/60], Step [110/140], Loss: 7.76274 , Acc: 73.28125  \n",
      "=====> Epoch [5/60], Step [120/140], Loss: 8.49767 , Acc: 69.84375  \n",
      "=====> Epoch [5/60], Step [130/140], Loss: 9.28121 , Acc: 68.75000  \n",
      "=====> Epoch [5/60], Step [140/140], Loss: 8.84320 , Acc: 72.34375  \n",
      "===> evaluating models...\n",
      "================\n",
      "val acc: 28.645833333333332 %  epoch: 5\n",
      "================\n",
      "===> Saving models...\n",
      "===> training models...\n",
      "=====> Epoch [6/60], Step [10/140], Loss: 6.40590 , Acc: 79.84375  \n",
      "=====> Epoch [6/60], Step [20/140], Loss: 6.14905 , Acc: 78.43750  \n",
      "=====> Epoch [6/60], Step [30/140], Loss: 7.01011 , Acc: 75.62500  \n",
      "=====> Epoch [6/60], Step [40/140], Loss: 7.14403 , Acc: 76.56250  \n",
      "=====> Epoch [6/60], Step [50/140], Loss: 7.34291 , Acc: 74.68750  \n",
      "=====> Epoch [6/60], Step [60/140], Loss: 8.28175 , Acc: 71.71875  \n",
      "=====> Epoch [6/60], Step [70/140], Loss: 7.65383 , Acc: 73.59375  \n",
      "=====> Epoch [6/60], Step [80/140], Loss: 8.25570 , Acc: 71.87500  \n",
      "=====> Epoch [6/60], Step [90/140], Loss: 7.92606 , Acc: 71.71875  \n",
      "=====> Epoch [6/60], Step [100/140], Loss: 7.71185 , Acc: 74.68750  \n",
      "=====> Epoch [6/60], Step [110/140], Loss: 7.97871 , Acc: 72.03125  \n",
      "=====> Epoch [6/60], Step [120/140], Loss: 9.26879 , Acc: 68.28125  \n",
      "=====> Epoch [6/60], Step [130/140], Loss: 8.12046 , Acc: 72.50000  \n",
      "=====> Epoch [6/60], Step [140/140], Loss: 8.11143 , Acc: 71.40625  \n",
      "===> evaluating models...\n",
      "================\n",
      "val acc: 40.625 %  epoch: 6\n",
      "================\n",
      "===> Saving models...\n",
      "===> training models...\n",
      "=====> Epoch [7/60], Step [10/140], Loss: 6.05598 , Acc: 79.84375  \n",
      "=====> Epoch [7/60], Step [20/140], Loss: 6.47348 , Acc: 77.65625  \n",
      "=====> Epoch [7/60], Step [30/140], Loss: 5.84758 , Acc: 80.15625  \n",
      "=====> Epoch [7/60], Step [40/140], Loss: 6.35326 , Acc: 78.75000  \n",
      "=====> Epoch [7/60], Step [50/140], Loss: 6.57322 , Acc: 79.06250  \n",
      "=====> Epoch [7/60], Step [60/140], Loss: 7.07365 , Acc: 74.21875  \n",
      "=====> Epoch [7/60], Step [70/140], Loss: 7.76790 , Acc: 73.59375  \n",
      "=====> Epoch [7/60], Step [80/140], Loss: 7.65703 , Acc: 73.28125  \n",
      "=====> Epoch [7/60], Step [90/140], Loss: 7.44955 , Acc: 73.90625  \n",
      "=====> Epoch [7/60], Step [100/140], Loss: 8.09087 , Acc: 73.12500  \n",
      "=====> Epoch [7/60], Step [110/140], Loss: 7.45793 , Acc: 76.56250  \n",
      "=====> Epoch [7/60], Step [120/140], Loss: 7.32299 , Acc: 73.43750  \n",
      "=====> Epoch [7/60], Step [130/140], Loss: 7.64314 , Acc: 73.43750  \n",
      "=====> Epoch [7/60], Step [140/140], Loss: 7.76765 , Acc: 73.90625  \n",
      "===> evaluating models...\n",
      "================\n",
      "val acc: 36.666666666666664 %  epoch: 7\n",
      "================\n",
      "===> training models...\n",
      "=====> Epoch [8/60], Step [10/140], Loss: 5.59960 , Acc: 82.81250  \n",
      "=====> Epoch [8/60], Step [20/140], Loss: 5.78051 , Acc: 80.78125  \n",
      "=====> Epoch [8/60], Step [30/140], Loss: 5.92338 , Acc: 79.21875  \n",
      "=====> Epoch [8/60], Step [40/140], Loss: 5.56220 , Acc: 82.34375  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====> Epoch [8/60], Step [50/140], Loss: 5.98132 , Acc: 79.06250  \n",
      "=====> Epoch [8/60], Step [60/140], Loss: 6.14948 , Acc: 79.53125  \n",
      "=====> Epoch [8/60], Step [70/140], Loss: 5.74046 , Acc: 80.93750  \n",
      "=====> Epoch [8/60], Step [80/140], Loss: 6.09406 , Acc: 79.21875  \n",
      "=====> Epoch [8/60], Step [90/140], Loss: 6.94632 , Acc: 76.09375  \n",
      "=====> Epoch [8/60], Step [100/140], Loss: 6.48710 , Acc: 78.43750  \n",
      "=====> Epoch [8/60], Step [110/140], Loss: 6.96084 , Acc: 75.00000  \n",
      "=====> Epoch [8/60], Step [120/140], Loss: 7.75871 , Acc: 73.90625  \n",
      "=====> Epoch [8/60], Step [130/140], Loss: 7.02122 , Acc: 77.03125  \n",
      "=====> Epoch [8/60], Step [140/140], Loss: 5.88104 , Acc: 79.68750  \n",
      "===> evaluating models...\n",
      "================\n",
      "val acc: 38.958333333333336 %  epoch: 8\n",
      "================\n",
      "===> training models...\n",
      "=====> Epoch [9/60], Step [10/140], Loss: 4.84505 , Acc: 84.06250  \n",
      "=====> Epoch [9/60], Step [20/140], Loss: 5.03034 , Acc: 82.96875  \n",
      "=====> Epoch [9/60], Step [30/140], Loss: 5.01456 , Acc: 82.65625  \n",
      "=====> Epoch [9/60], Step [40/140], Loss: 4.47912 , Acc: 84.68750  \n",
      "=====> Epoch [9/60], Step [50/140], Loss: 5.35062 , Acc: 82.03125  \n",
      "=====> Epoch [9/60], Step [60/140], Loss: 5.17412 , Acc: 82.50000  \n",
      "=====> Epoch [9/60], Step [70/140], Loss: 5.46472 , Acc: 82.03125  \n",
      "=====> Epoch [9/60], Step [80/140], Loss: 6.39022 , Acc: 77.50000  \n",
      "=====> Epoch [9/60], Step [90/140], Loss: 5.39965 , Acc: 81.56250  \n",
      "=====> Epoch [9/60], Step [100/140], Loss: 6.90033 , Acc: 76.56250  \n",
      "=====> Epoch [9/60], Step [110/140], Loss: 6.90801 , Acc: 77.03125  \n",
      "=====> Epoch [9/60], Step [120/140], Loss: 6.07991 , Acc: 79.53125  \n",
      "=====> Epoch [9/60], Step [130/140], Loss: 6.46691 , Acc: 78.28125  \n",
      "=====> Epoch [9/60], Step [140/140], Loss: 6.29232 , Acc: 77.50000  \n",
      "===> evaluating models...\n",
      "================\n",
      "val acc: 19.479166666666668 %  epoch: 9\n",
      "================\n",
      "===> training models...\n",
      "=====> Epoch [10/60], Step [10/140], Loss: 4.29063 , Acc: 86.25000  \n",
      "=====> Epoch [10/60], Step [20/140], Loss: 3.98030 , Acc: 87.18750  \n",
      "=====> Epoch [10/60], Step [30/140], Loss: 3.87853 , Acc: 88.59375  \n",
      "=====> Epoch [10/60], Step [40/140], Loss: 4.21740 , Acc: 85.15625  \n",
      "=====> Epoch [10/60], Step [50/140], Loss: 4.49405 , Acc: 84.21875  \n",
      "=====> Epoch [10/60], Step [60/140], Loss: 4.46216 , Acc: 83.43750  \n",
      "=====> Epoch [10/60], Step [70/140], Loss: 4.52942 , Acc: 84.37500  \n",
      "=====> Epoch [10/60], Step [80/140], Loss: 4.69657 , Acc: 82.81250  \n",
      "=====> Epoch [10/60], Step [90/140], Loss: 5.18114 , Acc: 82.81250  \n",
      "=====> Epoch [10/60], Step [100/140], Loss: 5.67936 , Acc: 80.00000  \n",
      "=====> Epoch [10/60], Step [110/140], Loss: 4.92786 , Acc: 82.81250  \n",
      "=====> Epoch [10/60], Step [120/140], Loss: 5.78258 , Acc: 81.56250  \n",
      "=====> Epoch [10/60], Step [130/140], Loss: 5.92046 , Acc: 78.59375  \n",
      "=====> Epoch [10/60], Step [140/140], Loss: 6.32811 , Acc: 79.68750  \n",
      "===> evaluating models...\n",
      "================\n",
      "val acc: 44.375 %  epoch: 10\n",
      "================\n",
      "===> Saving models...\n",
      "===> training models...\n",
      "=====> Epoch [11/60], Step [10/140], Loss: 3.88680 , Acc: 85.15625  \n",
      "=====> Epoch [11/60], Step [20/140], Loss: 3.23824 , Acc: 89.37500  \n",
      "=====> Epoch [11/60], Step [30/140], Loss: 3.89480 , Acc: 86.56250  \n",
      "=====> Epoch [11/60], Step [40/140], Loss: 3.91500 , Acc: 85.62500  \n",
      "=====> Epoch [11/60], Step [50/140], Loss: 4.24123 , Acc: 85.15625  \n",
      "=====> Epoch [11/60], Step [60/140], Loss: 3.56606 , Acc: 87.50000  \n",
      "=====> Epoch [11/60], Step [70/140], Loss: 4.47762 , Acc: 84.68750  \n",
      "=====> Epoch [11/60], Step [80/140], Loss: 4.78354 , Acc: 81.40625  \n",
      "=====> Epoch [11/60], Step [90/140], Loss: 4.77127 , Acc: 83.59375  \n",
      "=====> Epoch [11/60], Step [100/140], Loss: 5.32686 , Acc: 81.56250  \n",
      "=====> Epoch [11/60], Step [110/140], Loss: 4.84517 , Acc: 84.84375  \n",
      "=====> Epoch [11/60], Step [120/140], Loss: 4.80313 , Acc: 85.15625  \n",
      "=====> Epoch [11/60], Step [130/140], Loss: 5.25743 , Acc: 80.93750  \n",
      "=====> Epoch [11/60], Step [140/140], Loss: 5.47576 , Acc: 81.56250  \n",
      "===> evaluating models...\n",
      "================\n",
      "val acc: 51.979166666666664 %  epoch: 11\n",
      "================\n",
      "===> Saving models...\n",
      "===> training models...\n",
      "=====> Epoch [12/60], Step [10/140], Loss: 3.21890 , Acc: 88.59375  \n",
      "=====> Epoch [12/60], Step [20/140], Loss: 3.72200 , Acc: 87.18750  \n",
      "=====> Epoch [12/60], Step [30/140], Loss: 3.76332 , Acc: 87.81250  \n",
      "=====> Epoch [12/60], Step [40/140], Loss: 3.64980 , Acc: 87.50000  \n",
      "=====> Epoch [12/60], Step [50/140], Loss: 3.75826 , Acc: 88.59375  \n",
      "=====> Epoch [12/60], Step [60/140], Loss: 3.38704 , Acc: 88.75000  \n",
      "=====> Epoch [12/60], Step [70/140], Loss: 4.55472 , Acc: 85.78125  \n",
      "=====> Epoch [12/60], Step [80/140], Loss: 4.07962 , Acc: 85.78125  \n",
      "=====> Epoch [12/60], Step [90/140], Loss: 4.41929 , Acc: 85.00000  \n",
      "=====> Epoch [12/60], Step [100/140], Loss: 4.08544 , Acc: 85.46875  \n",
      "=====> Epoch [12/60], Step [110/140], Loss: 4.78627 , Acc: 83.75000  \n",
      "=====> Epoch [12/60], Step [120/140], Loss: 4.95381 , Acc: 82.65625  \n",
      "=====> Epoch [12/60], Step [130/140], Loss: 4.26420 , Acc: 84.37500  \n",
      "=====> Epoch [12/60], Step [140/140], Loss: 4.76495 , Acc: 83.59375  \n",
      "===> evaluating models...\n",
      "================\n",
      "val acc: 45.833333333333336 %  epoch: 12\n",
      "================\n",
      "===> training models...\n",
      "=====> Epoch [13/60], Step [10/140], Loss: 2.76342 , Acc: 91.71875  \n",
      "=====> Epoch [13/60], Step [20/140], Loss: 2.45702 , Acc: 90.78125  \n",
      "=====> Epoch [13/60], Step [30/140], Loss: 2.72140 , Acc: 90.93750  \n",
      "=====> Epoch [13/60], Step [40/140], Loss: 2.50749 , Acc: 91.09375  \n",
      "=====> Epoch [13/60], Step [50/140], Loss: 2.83996 , Acc: 90.00000  \n",
      "=====> Epoch [13/60], Step [60/140], Loss: 2.78520 , Acc: 91.09375  \n",
      "=====> Epoch [13/60], Step [70/140], Loss: 3.11580 , Acc: 88.59375  \n",
      "=====> Epoch [13/60], Step [80/140], Loss: 3.47875 , Acc: 89.06250  \n",
      "=====> Epoch [13/60], Step [90/140], Loss: 3.40483 , Acc: 88.59375  \n",
      "=====> Epoch [13/60], Step [100/140], Loss: 3.60925 , Acc: 86.71875  \n",
      "=====> Epoch [13/60], Step [110/140], Loss: 4.28934 , Acc: 84.06250  \n",
      "=====> Epoch [13/60], Step [120/140], Loss: 3.76617 , Acc: 86.71875  \n",
      "=====> Epoch [13/60], Step [130/140], Loss: 3.71922 , Acc: 86.25000  \n",
      "=====> Epoch [13/60], Step [140/140], Loss: 4.26155 , Acc: 84.84375  \n",
      "===> evaluating models...\n",
      "================\n",
      "val acc: 38.333333333333336 %  epoch: 13\n",
      "================\n",
      "===> training models...\n",
      "=====> Epoch [14/60], Step [10/140], Loss: 2.72829 , Acc: 91.40625  \n",
      "=====> Epoch [14/60], Step [20/140], Loss: 2.18301 , Acc: 93.28125  \n",
      "=====> Epoch [14/60], Step [30/140], Loss: 2.69425 , Acc: 91.09375  \n",
      "=====> Epoch [14/60], Step [40/140], Loss: 2.62931 , Acc: 91.09375  \n",
      "=====> Epoch [14/60], Step [50/140], Loss: 2.24820 , Acc: 92.65625  \n",
      "=====> Epoch [14/60], Step [60/140], Loss: 2.24459 , Acc: 92.34375  \n",
      "=====> Epoch [14/60], Step [70/140], Loss: 2.66765 , Acc: 91.09375  \n",
      "=====> Epoch [14/60], Step [80/140], Loss: 2.98020 , Acc: 88.90625  \n",
      "=====> Epoch [14/60], Step [90/140], Loss: 3.78234 , Acc: 87.03125  \n",
      "=====> Epoch [14/60], Step [100/140], Loss: 3.62533 , Acc: 88.43750  \n",
      "=====> Epoch [14/60], Step [110/140], Loss: 3.66260 , Acc: 87.65625  \n",
      "=====> Epoch [14/60], Step [120/140], Loss: 3.75191 , Acc: 86.25000  \n",
      "=====> Epoch [14/60], Step [130/140], Loss: 3.31053 , Acc: 88.43750  \n",
      "=====> Epoch [14/60], Step [140/140], Loss: 3.42498 , Acc: 88.12500  \n",
      "===> evaluating models...\n",
      "================\n",
      "val acc: 53.333333333333336 %  epoch: 14\n",
      "================\n",
      "===> Saving models...\n",
      "===> training models...\n",
      "=====> Epoch [15/60], Step [10/140], Loss: 2.49756 , Acc: 90.93750  \n",
      "=====> Epoch [15/60], Step [20/140], Loss: 2.11314 , Acc: 93.43750  \n",
      "=====> Epoch [15/60], Step [30/140], Loss: 2.46113 , Acc: 91.40625  \n",
      "=====> Epoch [15/60], Step [40/140], Loss: 2.44309 , Acc: 92.03125  \n",
      "=====> Epoch [15/60], Step [50/140], Loss: 2.52915 , Acc: 91.56250  \n",
      "=====> Epoch [15/60], Step [60/140], Loss: 2.38512 , Acc: 91.25000  \n",
      "=====> Epoch [15/60], Step [70/140], Loss: 2.33812 , Acc: 92.50000  \n",
      "=====> Epoch [15/60], Step [80/140], Loss: 2.83093 , Acc: 91.40625  \n",
      "=====> Epoch [15/60], Step [90/140], Loss: 2.16770 , Acc: 93.75000  \n",
      "=====> Epoch [15/60], Step [100/140], Loss: 2.46863 , Acc: 91.25000  \n",
      "=====> Epoch [15/60], Step [110/140], Loss: 2.91124 , Acc: 89.37500  \n",
      "=====> Epoch [15/60], Step [120/140], Loss: 2.89559 , Acc: 90.31250  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====> Epoch [15/60], Step [130/140], Loss: 3.17294 , Acc: 88.59375  \n",
      "=====> Epoch [15/60], Step [140/140], Loss: 3.36323 , Acc: 87.96875  \n",
      "===> evaluating models...\n",
      "================\n",
      "val acc: 54.0625 %  epoch: 15\n",
      "================\n",
      "===> Saving models...\n",
      "===> training models...\n",
      "=====> Epoch [16/60], Step [10/140], Loss: 1.86417 , Acc: 94.06250  \n",
      "=====> Epoch [16/60], Step [20/140], Loss: 2.69176 , Acc: 90.62500  \n",
      "=====> Epoch [16/60], Step [30/140], Loss: 2.72382 , Acc: 90.93750  \n",
      "=====> Epoch [16/60], Step [40/140], Loss: 3.03129 , Acc: 89.06250  \n",
      "=====> Epoch [16/60], Step [50/140], Loss: 2.68496 , Acc: 89.68750  \n",
      "=====> Epoch [16/60], Step [60/140], Loss: 2.36161 , Acc: 92.65625  \n",
      "=====> Epoch [16/60], Step [70/140], Loss: 2.93459 , Acc: 89.37500  \n",
      "=====> Epoch [16/60], Step [80/140], Loss: 2.94199 , Acc: 89.21875  \n",
      "=====> Epoch [16/60], Step [90/140], Loss: 3.49068 , Acc: 88.90625  \n",
      "=====> Epoch [16/60], Step [100/140], Loss: 4.16180 , Acc: 86.40625  \n",
      "=====> Epoch [16/60], Step [110/140], Loss: 3.32543 , Acc: 87.65625  \n",
      "=====> Epoch [16/60], Step [120/140], Loss: 3.62201 , Acc: 88.43750  \n",
      "=====> Epoch [16/60], Step [130/140], Loss: 2.99569 , Acc: 90.15625  \n",
      "=====> Epoch [16/60], Step [140/140], Loss: 3.19593 , Acc: 89.06250  \n",
      "===> evaluating models...\n",
      "================\n",
      "val acc: 55.625 %  epoch: 16\n",
      "================\n",
      "===> Saving models...\n",
      "===> training models...\n",
      "=====> Epoch [17/60], Step [10/140], Loss: 1.87699 , Acc: 93.28125  \n",
      "=====> Epoch [17/60], Step [20/140], Loss: 1.63735 , Acc: 95.15625  \n",
      "=====> Epoch [17/60], Step [30/140], Loss: 1.74096 , Acc: 94.53125  \n",
      "=====> Epoch [17/60], Step [40/140], Loss: 1.78620 , Acc: 93.59375  \n",
      "=====> Epoch [17/60], Step [50/140], Loss: 1.88939 , Acc: 94.37500  \n",
      "=====> Epoch [17/60], Step [60/140], Loss: 1.58953 , Acc: 93.90625  \n",
      "=====> Epoch [17/60], Step [70/140], Loss: 2.34332 , Acc: 92.18750  \n",
      "=====> Epoch [17/60], Step [80/140], Loss: 1.96256 , Acc: 93.28125  \n",
      "=====> Epoch [17/60], Step [90/140], Loss: 2.01788 , Acc: 93.75000  \n",
      "=====> Epoch [17/60], Step [100/140], Loss: 2.06657 , Acc: 93.43750  \n",
      "=====> Epoch [17/60], Step [110/140], Loss: 2.43300 , Acc: 92.34375  \n",
      "=====> Epoch [17/60], Step [120/140], Loss: 2.14555 , Acc: 91.56250  \n",
      "=====> Epoch [17/60], Step [130/140], Loss: 2.56870 , Acc: 90.15625  \n",
      "=====> Epoch [17/60], Step [140/140], Loss: 2.04140 , Acc: 93.90625  \n",
      "===> evaluating models...\n",
      "================\n",
      "val acc: 45.208333333333336 %  epoch: 17\n",
      "================\n",
      "===> training models...\n",
      "=====> Epoch [18/60], Step [10/140], Loss: 1.56469 , Acc: 94.84375  \n",
      "=====> Epoch [18/60], Step [20/140], Loss: 1.44266 , Acc: 94.84375  \n",
      "=====> Epoch [18/60], Step [30/140], Loss: 1.21973 , Acc: 95.93750  \n",
      "=====> Epoch [18/60], Step [40/140], Loss: 1.62953 , Acc: 94.68750  \n",
      "=====> Epoch [18/60], Step [50/140], Loss: 1.91204 , Acc: 94.06250  \n",
      "=====> Epoch [18/60], Step [60/140], Loss: 2.06712 , Acc: 92.34375  \n",
      "=====> Epoch [18/60], Step [70/140], Loss: 2.24308 , Acc: 92.18750  \n",
      "=====> Epoch [18/60], Step [80/140], Loss: 2.47063 , Acc: 89.84375  \n",
      "=====> Epoch [18/60], Step [90/140], Loss: 2.12289 , Acc: 92.96875  \n",
      "=====> Epoch [18/60], Step [100/140], Loss: 2.07882 , Acc: 93.90625  \n",
      "=====> Epoch [18/60], Step [110/140], Loss: 2.95008 , Acc: 89.84375  \n",
      "=====> Epoch [18/60], Step [120/140], Loss: 2.29132 , Acc: 90.93750  \n",
      "=====> Epoch [18/60], Step [130/140], Loss: 2.43216 , Acc: 92.96875  \n",
      "=====> Epoch [18/60], Step [140/140], Loss: 2.30449 , Acc: 92.96875  \n",
      "===> evaluating models...\n",
      "================\n",
      "val acc: 56.041666666666664 %  epoch: 18\n",
      "================\n",
      "===> Saving models...\n",
      "===> training models...\n",
      "=====> Epoch [19/60], Step [10/140], Loss: 1.98379 , Acc: 93.28125  \n",
      "=====> Epoch [19/60], Step [20/140], Loss: 2.03282 , Acc: 93.12500  \n",
      "=====> Epoch [19/60], Step [30/140], Loss: 1.74883 , Acc: 93.12500  \n",
      "=====> Epoch [19/60], Step [40/140], Loss: 1.64376 , Acc: 94.68750  \n",
      "=====> Epoch [19/60], Step [50/140], Loss: 1.70707 , Acc: 93.43750  \n",
      "=====> Epoch [19/60], Step [60/140], Loss: 1.89570 , Acc: 93.43750  \n",
      "=====> Epoch [19/60], Step [70/140], Loss: 1.74993 , Acc: 93.90625  \n",
      "=====> Epoch [19/60], Step [80/140], Loss: 2.04175 , Acc: 92.50000  \n",
      "=====> Epoch [19/60], Step [90/140], Loss: 1.93375 , Acc: 93.59375  \n",
      "=====> Epoch [19/60], Step [100/140], Loss: 1.81744 , Acc: 92.50000  \n",
      "=====> Epoch [19/60], Step [110/140], Loss: 2.13780 , Acc: 93.28125  \n",
      "=====> Epoch [19/60], Step [120/140], Loss: 2.20409 , Acc: 93.28125  \n",
      "=====> Epoch [19/60], Step [130/140], Loss: 2.21893 , Acc: 92.81250  \n",
      "=====> Epoch [19/60], Step [140/140], Loss: 2.47411 , Acc: 91.87500  \n",
      "===> evaluating models...\n",
      "================\n",
      "val acc: 41.666666666666664 %  epoch: 19\n",
      "================\n",
      "===> training models...\n",
      "=====> Epoch [20/60], Step [10/140], Loss: 1.78491 , Acc: 94.37500  \n",
      "=====> Epoch [20/60], Step [20/140], Loss: 1.76518 , Acc: 94.06250  \n",
      "=====> Epoch [20/60], Step [30/140], Loss: 1.64430 , Acc: 94.06250  \n",
      "=====> Epoch [20/60], Step [40/140], Loss: 1.29455 , Acc: 95.93750  \n",
      "=====> Epoch [20/60], Step [50/140], Loss: 2.45289 , Acc: 92.96875  \n",
      "=====> Epoch [20/60], Step [60/140], Loss: 2.22392 , Acc: 92.18750  \n",
      "=====> Epoch [20/60], Step [70/140], Loss: 2.39421 , Acc: 91.40625  \n",
      "=====> Epoch [20/60], Step [80/140], Loss: 2.23769 , Acc: 92.96875  \n",
      "=====> Epoch [20/60], Step [90/140], Loss: 2.23208 , Acc: 92.34375  \n",
      "=====> Epoch [20/60], Step [100/140], Loss: 1.92573 , Acc: 92.65625  \n",
      "=====> Epoch [20/60], Step [110/140], Loss: 2.02675 , Acc: 92.65625  \n",
      "=====> Epoch [20/60], Step [120/140], Loss: 2.96197 , Acc: 90.31250  \n",
      "=====> Epoch [20/60], Step [130/140], Loss: 2.78566 , Acc: 90.78125  \n",
      "=====> Epoch [20/60], Step [140/140], Loss: 2.40032 , Acc: 91.71875  \n",
      "===> evaluating models...\n",
      "================\n",
      "val acc: 55.729166666666664 %  epoch: 20\n",
      "================\n",
      "===> training models...\n",
      "=====> Epoch [21/60], Step [10/140], Loss: 1.97706 , Acc: 92.34375  \n",
      "=====> Epoch [21/60], Step [20/140], Loss: 1.78734 , Acc: 94.53125  \n",
      "=====> Epoch [21/60], Step [30/140], Loss: 1.81539 , Acc: 93.75000  \n",
      "=====> Epoch [21/60], Step [40/140], Loss: 1.52353 , Acc: 96.09375  \n",
      "=====> Epoch [21/60], Step [50/140], Loss: 1.72207 , Acc: 93.75000  \n",
      "=====> Epoch [21/60], Step [60/140], Loss: 1.63749 , Acc: 95.15625  \n",
      "=====> Epoch [21/60], Step [70/140], Loss: 1.74040 , Acc: 94.21875  \n",
      "=====> Epoch [21/60], Step [80/140], Loss: 1.96882 , Acc: 93.59375  \n",
      "=====> Epoch [21/60], Step [90/140], Loss: 1.79569 , Acc: 94.21875  \n",
      "=====> Epoch [21/60], Step [100/140], Loss: 1.79977 , Acc: 94.21875  \n",
      "=====> Epoch [21/60], Step [110/140], Loss: 2.02620 , Acc: 92.50000  \n",
      "=====> Epoch [21/60], Step [120/140], Loss: 1.94868 , Acc: 93.59375  \n",
      "=====> Epoch [21/60], Step [130/140], Loss: 1.54361 , Acc: 95.62500  \n",
      "=====> Epoch [21/60], Step [140/140], Loss: 2.04819 , Acc: 92.96875  \n",
      "===> evaluating models...\n",
      "================\n",
      "val acc: 60.416666666666664 %  epoch: 21\n",
      "================\n",
      "===> Saving models...\n",
      "===> training models...\n",
      "=====> Epoch [22/60], Step [10/140], Loss: 0.99760 , Acc: 96.71875  \n",
      "=====> Epoch [22/60], Step [20/140], Loss: 1.24822 , Acc: 96.56250  \n",
      "=====> Epoch [22/60], Step [30/140], Loss: 0.96965 , Acc: 96.71875  \n",
      "=====> Epoch [22/60], Step [40/140], Loss: 1.28289 , Acc: 96.25000  \n",
      "=====> Epoch [22/60], Step [50/140], Loss: 1.29629 , Acc: 95.46875  \n",
      "=====> Epoch [22/60], Step [60/140], Loss: 1.18761 , Acc: 96.25000  \n",
      "=====> Epoch [22/60], Step [70/140], Loss: 1.63198 , Acc: 94.53125  \n",
      "=====> Epoch [22/60], Step [80/140], Loss: 2.03277 , Acc: 93.75000  \n",
      "=====> Epoch [22/60], Step [90/140], Loss: 2.86108 , Acc: 90.93750  \n",
      "=====> Epoch [22/60], Step [100/140], Loss: 2.09227 , Acc: 93.43750  \n",
      "=====> Epoch [22/60], Step [110/140], Loss: 2.43874 , Acc: 91.09375  \n",
      "=====> Epoch [22/60], Step [120/140], Loss: 2.80080 , Acc: 89.53125  \n",
      "=====> Epoch [22/60], Step [130/140], Loss: 2.51537 , Acc: 91.71875  \n",
      "=====> Epoch [22/60], Step [140/140], Loss: 2.93327 , Acc: 90.31250  \n",
      "===> evaluating models...\n",
      "================\n",
      "val acc: 63.854166666666664 %  epoch: 22\n",
      "================\n",
      "===> Saving models...\n",
      "===> training models...\n",
      "=====> Epoch [23/60], Step [10/140], Loss: 1.55235 , Acc: 94.68750  \n",
      "=====> Epoch [23/60], Step [20/140], Loss: 1.59042 , Acc: 94.21875  \n",
      "=====> Epoch [23/60], Step [30/140], Loss: 1.18095 , Acc: 97.34375  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====> Epoch [23/60], Step [40/140], Loss: 1.48558 , Acc: 95.78125  \n",
      "=====> Epoch [23/60], Step [50/140], Loss: 1.41054 , Acc: 96.09375  \n",
      "=====> Epoch [23/60], Step [60/140], Loss: 1.28526 , Acc: 96.09375  \n",
      "=====> Epoch [23/60], Step [70/140], Loss: 1.36480 , Acc: 95.15625  \n",
      "=====> Epoch [23/60], Step [80/140], Loss: 1.50220 , Acc: 95.46875  \n",
      "=====> Epoch [23/60], Step [90/140], Loss: 1.45852 , Acc: 94.68750  \n",
      "=====> Epoch [23/60], Step [100/140], Loss: 1.51404 , Acc: 95.00000  \n",
      "=====> Epoch [23/60], Step [110/140], Loss: 1.60310 , Acc: 94.84375  \n",
      "=====> Epoch [23/60], Step [120/140], Loss: 1.61363 , Acc: 93.75000  \n",
      "=====> Epoch [23/60], Step [130/140], Loss: 1.36316 , Acc: 95.00000  \n",
      "=====> Epoch [23/60], Step [140/140], Loss: 1.76671 , Acc: 93.75000  \n",
      "===> evaluating models...\n",
      "================\n",
      "val acc: 48.645833333333336 %  epoch: 23\n",
      "================\n",
      "===> training models...\n",
      "=====> Epoch [24/60], Step [10/140], Loss: 1.28197 , Acc: 96.09375  \n",
      "=====> Epoch [24/60], Step [20/140], Loss: 1.43781 , Acc: 95.62500  \n",
      "=====> Epoch [24/60], Step [30/140], Loss: 1.58733 , Acc: 94.06250  \n",
      "=====> Epoch [24/60], Step [40/140], Loss: 1.38101 , Acc: 95.15625  \n",
      "=====> Epoch [24/60], Step [50/140], Loss: 1.61346 , Acc: 94.53125  \n",
      "=====> Epoch [24/60], Step [60/140], Loss: 1.43571 , Acc: 95.31250  \n",
      "=====> Epoch [24/60], Step [70/140], Loss: 1.41270 , Acc: 94.84375  \n",
      "=====> Epoch [24/60], Step [80/140], Loss: 1.53323 , Acc: 94.06250  \n",
      "=====> Epoch [24/60], Step [90/140], Loss: 1.64475 , Acc: 94.53125  \n",
      "=====> Epoch [24/60], Step [100/140], Loss: 1.47258 , Acc: 94.53125  \n",
      "=====> Epoch [24/60], Step [110/140], Loss: 1.71690 , Acc: 93.75000  \n",
      "=====> Epoch [24/60], Step [120/140], Loss: 1.88926 , Acc: 93.75000  \n",
      "=====> Epoch [24/60], Step [130/140], Loss: 1.90940 , Acc: 93.59375  \n",
      "=====> Epoch [24/60], Step [140/140], Loss: 2.39773 , Acc: 92.18750  \n",
      "===> evaluating models...\n",
      "================\n",
      "val acc: 56.875 %  epoch: 24\n",
      "================\n",
      "===> training models...\n",
      "=====> Epoch [25/60], Step [10/140], Loss: 1.56613 , Acc: 94.68750  \n",
      "=====> Epoch [25/60], Step [20/140], Loss: 1.38965 , Acc: 95.15625  \n",
      "=====> Epoch [25/60], Step [30/140], Loss: 1.16878 , Acc: 96.40625  \n",
      "=====> Epoch [25/60], Step [40/140], Loss: 1.04308 , Acc: 96.71875  \n",
      "=====> Epoch [25/60], Step [50/140], Loss: 1.24277 , Acc: 95.78125  \n",
      "=====> Epoch [25/60], Step [60/140], Loss: 0.88224 , Acc: 97.03125  \n",
      "=====> Epoch [25/60], Step [70/140], Loss: 1.35291 , Acc: 95.00000  \n",
      "=====> Epoch [25/60], Step [80/140], Loss: 1.31684 , Acc: 95.62500  \n",
      "=====> Epoch [25/60], Step [90/140], Loss: 1.63248 , Acc: 93.75000  \n",
      "=====> Epoch [25/60], Step [100/140], Loss: 1.92230 , Acc: 93.75000  \n",
      "=====> Epoch [25/60], Step [110/140], Loss: 1.77757 , Acc: 94.06250  \n",
      "=====> Epoch [25/60], Step [120/140], Loss: 1.33769 , Acc: 94.84375  \n",
      "=====> Epoch [25/60], Step [130/140], Loss: 1.40956 , Acc: 94.37500  \n",
      "=====> Epoch [25/60], Step [140/140], Loss: 1.54941 , Acc: 95.00000  \n",
      "===> evaluating models...\n",
      "================\n",
      "val acc: 55.833333333333336 %  epoch: 25\n",
      "================\n",
      "===> training models...\n",
      "=====> Epoch [26/60], Step [10/140], Loss: 1.06088 , Acc: 95.62500  \n",
      "=====> Epoch [26/60], Step [20/140], Loss: 1.30024 , Acc: 95.31250  \n",
      "=====> Epoch [26/60], Step [30/140], Loss: 1.21999 , Acc: 95.46875  \n",
      "=====> Epoch [26/60], Step [40/140], Loss: 1.40042 , Acc: 95.62500  \n",
      "=====> Epoch [26/60], Step [50/140], Loss: 1.33949 , Acc: 96.09375  \n",
      "=====> Epoch [26/60], Step [60/140], Loss: 1.67648 , Acc: 93.75000  \n",
      "=====> Epoch [26/60], Step [70/140], Loss: 1.64338 , Acc: 94.68750  \n",
      "=====> Epoch [26/60], Step [80/140], Loss: 1.43689 , Acc: 95.62500  \n",
      "=====> Epoch [26/60], Step [90/140], Loss: 1.72439 , Acc: 94.53125  \n",
      "=====> Epoch [26/60], Step [100/140], Loss: 2.06279 , Acc: 92.81250  \n",
      "=====> Epoch [26/60], Step [110/140], Loss: 1.53113 , Acc: 95.15625  \n",
      "=====> Epoch [26/60], Step [120/140], Loss: 1.54636 , Acc: 94.53125  \n",
      "=====> Epoch [26/60], Step [130/140], Loss: 1.62457 , Acc: 94.53125  \n",
      "=====> Epoch [26/60], Step [140/140], Loss: 1.75433 , Acc: 93.75000  \n",
      "===> evaluating models...\n",
      "================\n",
      "val acc: 59.375 %  epoch: 26\n",
      "================\n",
      "===> training models...\n",
      "=====> Epoch [27/60], Step [10/140], Loss: 0.94453 , Acc: 97.18750  \n",
      "=====> Epoch [27/60], Step [20/140], Loss: 1.28732 , Acc: 96.40625  \n",
      "=====> Epoch [27/60], Step [30/140], Loss: 1.24386 , Acc: 96.71875  \n",
      "=====> Epoch [27/60], Step [40/140], Loss: 1.26711 , Acc: 95.62500  \n",
      "=====> Epoch [27/60], Step [50/140], Loss: 1.38894 , Acc: 94.53125  \n",
      "=====> Epoch [27/60], Step [60/140], Loss: 1.04682 , Acc: 96.09375  \n",
      "=====> Epoch [27/60], Step [70/140], Loss: 1.48766 , Acc: 94.84375  \n",
      "=====> Epoch [27/60], Step [80/140], Loss: 1.49495 , Acc: 94.53125  \n",
      "=====> Epoch [27/60], Step [90/140], Loss: 1.53691 , Acc: 95.00000  \n",
      "=====> Epoch [27/60], Step [100/140], Loss: 1.81351 , Acc: 93.90625  \n",
      "=====> Epoch [27/60], Step [110/140], Loss: 1.77848 , Acc: 93.90625  \n",
      "=====> Epoch [27/60], Step [120/140], Loss: 1.94337 , Acc: 93.12500  \n",
      "=====> Epoch [27/60], Step [130/140], Loss: 2.33266 , Acc: 90.78125  \n",
      "=====> Epoch [27/60], Step [140/140], Loss: 1.86559 , Acc: 93.12500  \n",
      "===> evaluating models...\n",
      "================\n",
      "val acc: 61.041666666666664 %  epoch: 27\n",
      "================\n",
      "===> training models...\n",
      "=====> Epoch [28/60], Step [10/140], Loss: 1.27602 , Acc: 95.93750  \n",
      "=====> Epoch [28/60], Step [20/140], Loss: 1.48260 , Acc: 95.62500  \n",
      "=====> Epoch [28/60], Step [30/140], Loss: 1.12119 , Acc: 96.09375  \n",
      "=====> Epoch [28/60], Step [40/140], Loss: 2.11351 , Acc: 92.81250  \n",
      "=====> Epoch [28/60], Step [50/140], Loss: 1.71252 , Acc: 94.37500  \n",
      "=====> Epoch [28/60], Step [60/140], Loss: 1.60385 , Acc: 94.06250  \n",
      "=====> Epoch [28/60], Step [70/140], Loss: 1.72777 , Acc: 94.21875  \n",
      "=====> Epoch [28/60], Step [80/140], Loss: 1.46912 , Acc: 95.46875  \n",
      "=====> Epoch [28/60], Step [90/140], Loss: 1.38930 , Acc: 96.09375  \n",
      "=====> Epoch [28/60], Step [100/140], Loss: 1.42887 , Acc: 95.46875  \n",
      "=====> Epoch [28/60], Step [110/140], Loss: 1.61930 , Acc: 94.37500  \n",
      "=====> Epoch [28/60], Step [120/140], Loss: 1.80781 , Acc: 94.37500  \n",
      "=====> Epoch [28/60], Step [130/140], Loss: 1.58114 , Acc: 94.68750  \n",
      "=====> Epoch [28/60], Step [140/140], Loss: 1.48618 , Acc: 93.75000  \n",
      "===> evaluating models...\n",
      "================\n",
      "val acc: 59.479166666666664 %  epoch: 28\n",
      "================\n",
      "===> training models...\n",
      "=====> Epoch [29/60], Step [10/140], Loss: 0.81474 , Acc: 96.56250  \n",
      "=====> Epoch [29/60], Step [20/140], Loss: 0.99234 , Acc: 96.56250  \n",
      "=====> Epoch [29/60], Step [30/140], Loss: 1.14727 , Acc: 96.09375  \n",
      "=====> Epoch [29/60], Step [40/140], Loss: 0.75866 , Acc: 97.65625  \n",
      "=====> Epoch [29/60], Step [50/140], Loss: 1.21336 , Acc: 95.00000  \n",
      "=====> Epoch [29/60], Step [60/140], Loss: 0.79765 , Acc: 97.65625  \n",
      "=====> Epoch [29/60], Step [70/140], Loss: 1.19518 , Acc: 96.25000  \n",
      "=====> Epoch [29/60], Step [80/140], Loss: 1.02144 , Acc: 96.87500  \n",
      "=====> Epoch [29/60], Step [90/140], Loss: 1.38790 , Acc: 94.84375  \n",
      "=====> Epoch [29/60], Step [100/140], Loss: 1.46419 , Acc: 94.37500  \n",
      "=====> Epoch [29/60], Step [110/140], Loss: 1.62113 , Acc: 94.84375  \n",
      "=====> Epoch [29/60], Step [120/140], Loss: 1.50403 , Acc: 93.75000  \n",
      "=====> Epoch [29/60], Step [130/140], Loss: 2.05817 , Acc: 92.34375  \n",
      "=====> Epoch [29/60], Step [140/140], Loss: 1.95173 , Acc: 93.90625  \n",
      "===> evaluating models...\n",
      "================\n",
      "val acc: 59.6875 %  epoch: 29\n",
      "================\n",
      "===> training models...\n",
      "=====> Epoch [30/60], Step [10/140], Loss: 1.15805 , Acc: 96.40625  \n",
      "=====> Epoch [30/60], Step [20/140], Loss: 0.92132 , Acc: 97.34375  \n",
      "=====> Epoch [30/60], Step [30/140], Loss: 0.85227 , Acc: 96.87500  \n",
      "=====> Epoch [30/60], Step [40/140], Loss: 0.88983 , Acc: 97.18750  \n",
      "=====> Epoch [30/60], Step [50/140], Loss: 0.82641 , Acc: 97.03125  \n",
      "=====> Epoch [30/60], Step [60/140], Loss: 0.78804 , Acc: 97.18750  \n",
      "=====> Epoch [30/60], Step [70/140], Loss: 0.83119 , Acc: 97.18750  \n",
      "=====> Epoch [30/60], Step [80/140], Loss: 0.47593 , Acc: 98.12500  \n",
      "=====> Epoch [30/60], Step [90/140], Loss: 0.61047 , Acc: 98.43750  \n",
      "=====> Epoch [30/60], Step [100/140], Loss: 0.62849 , Acc: 98.75000  \n",
      "=====> Epoch [30/60], Step [110/140], Loss: 0.52671 , Acc: 98.12500  \n",
      "=====> Epoch [30/60], Step [120/140], Loss: 0.32074 , Acc: 99.53125  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====> Epoch [30/60], Step [130/140], Loss: 0.49367 , Acc: 98.90625  \n",
      "=====> Epoch [30/60], Step [140/140], Loss: 0.37234 , Acc: 98.90625  \n",
      "===> evaluating models...\n",
      "================\n",
      "val acc: 66.66666666666667 %  epoch: 30\n",
      "================\n",
      "===> Saving models...\n",
      "===> training models...\n",
      "=====> Epoch [31/60], Step [10/140], Loss: 0.30924 , Acc: 99.21875  \n",
      "=====> Epoch [31/60], Step [20/140], Loss: 0.23725 , Acc: 99.53125  \n",
      "=====> Epoch [31/60], Step [30/140], Loss: 0.28382 , Acc: 99.37500  \n",
      "=====> Epoch [31/60], Step [40/140], Loss: 0.25535 , Acc: 99.53125  \n",
      "=====> Epoch [31/60], Step [50/140], Loss: 0.25639 , Acc: 99.37500  \n",
      "=====> Epoch [31/60], Step [60/140], Loss: 0.26249 , Acc: 99.21875  \n",
      "=====> Epoch [31/60], Step [70/140], Loss: 0.19483 , Acc: 99.53125  \n",
      "=====> Epoch [31/60], Step [80/140], Loss: 0.20432 , Acc: 99.53125  \n",
      "=====> Epoch [31/60], Step [90/140], Loss: 0.22360 , Acc: 99.68750  \n",
      "=====> Epoch [31/60], Step [100/140], Loss: 0.22262 , Acc: 99.53125  \n",
      "=====> Epoch [31/60], Step [110/140], Loss: 0.20293 , Acc: 99.68750  \n",
      "=====> Epoch [31/60], Step [120/140], Loss: 0.16534 , Acc: 99.84375  \n",
      "=====> Epoch [31/60], Step [130/140], Loss: 0.17027 , Acc: 99.68750  \n",
      "=====> Epoch [31/60], Step [140/140], Loss: 0.30759 , Acc: 99.06250  \n",
      "===> evaluating models...\n",
      "================\n",
      "val acc: 67.29166666666667 %  epoch: 31\n",
      "================\n",
      "===> Saving models...\n",
      "===> training models...\n",
      "=====> Epoch [32/60], Step [10/140], Loss: 0.20561 , Acc: 99.68750  \n",
      "=====> Epoch [32/60], Step [20/140], Loss: 0.17839 , Acc: 99.84375  \n",
      "=====> Epoch [32/60], Step [30/140], Loss: 0.11562 , Acc: 100.00000  \n",
      "=====> Epoch [32/60], Step [40/140], Loss: 0.15934 , Acc: 99.84375  \n",
      "=====> Epoch [32/60], Step [50/140], Loss: 0.14444 , Acc: 99.84375  \n",
      "=====> Epoch [32/60], Step [60/140], Loss: 0.16016 , Acc: 99.84375  \n",
      "=====> Epoch [32/60], Step [70/140], Loss: 0.14547 , Acc: 99.84375  \n",
      "=====> Epoch [32/60], Step [80/140], Loss: 0.16172 , Acc: 99.68750  \n",
      "=====> Epoch [32/60], Step [90/140], Loss: 0.17085 , Acc: 99.53125  \n",
      "=====> Epoch [32/60], Step [100/140], Loss: 0.16236 , Acc: 99.84375  \n",
      "=====> Epoch [32/60], Step [110/140], Loss: 0.11569 , Acc: 99.84375  \n",
      "=====> Epoch [32/60], Step [120/140], Loss: 0.18233 , Acc: 99.68750  \n",
      "=====> Epoch [32/60], Step [130/140], Loss: 0.19228 , Acc: 99.68750  \n",
      "=====> Epoch [32/60], Step [140/140], Loss: 0.12148 , Acc: 100.00000  \n",
      "===> evaluating models...\n",
      "================\n",
      "val acc: 68.02083333333333 %  epoch: 32\n",
      "================\n",
      "===> Saving models...\n",
      "===> training models...\n",
      "=====> Epoch [33/60], Step [10/140], Loss: 0.13231 , Acc: 100.00000  \n",
      "=====> Epoch [33/60], Step [20/140], Loss: 0.17562 , Acc: 99.68750  \n",
      "=====> Epoch [33/60], Step [30/140], Loss: 0.14605 , Acc: 99.68750  \n",
      "=====> Epoch [33/60], Step [40/140], Loss: 0.10367 , Acc: 100.00000  \n",
      "=====> Epoch [33/60], Step [50/140], Loss: 0.08210 , Acc: 99.84375  \n",
      "=====> Epoch [33/60], Step [60/140], Loss: 0.12846 , Acc: 99.84375  \n",
      "=====> Epoch [33/60], Step [70/140], Loss: 0.11594 , Acc: 99.84375  \n",
      "=====> Epoch [33/60], Step [80/140], Loss: 0.11710 , Acc: 99.84375  \n",
      "=====> Epoch [33/60], Step [90/140], Loss: 0.14833 , Acc: 99.84375  \n",
      "=====> Epoch [33/60], Step [100/140], Loss: 0.12382 , Acc: 100.00000  \n",
      "=====> Epoch [33/60], Step [110/140], Loss: 0.15012 , Acc: 99.84375  \n",
      "=====> Epoch [33/60], Step [120/140], Loss: 0.14087 , Acc: 99.84375  \n",
      "=====> Epoch [33/60], Step [130/140], Loss: 0.07526 , Acc: 100.00000  \n",
      "=====> Epoch [33/60], Step [140/140], Loss: 0.09332 , Acc: 100.00000  \n",
      "===> evaluating models...\n",
      "================\n",
      "val acc: 68.22916666666667 %  epoch: 33\n",
      "================\n",
      "===> Saving models...\n",
      "===> training models...\n",
      "=====> Epoch [34/60], Step [10/140], Loss: 0.07962 , Acc: 100.00000  \n",
      "=====> Epoch [34/60], Step [20/140], Loss: 0.09024 , Acc: 99.84375  \n",
      "=====> Epoch [34/60], Step [30/140], Loss: 0.11539 , Acc: 100.00000  \n",
      "=====> Epoch [34/60], Step [40/140], Loss: 0.10961 , Acc: 99.68750  \n",
      "=====> Epoch [34/60], Step [50/140], Loss: 0.08544 , Acc: 100.00000  \n",
      "=====> Epoch [34/60], Step [60/140], Loss: 0.09723 , Acc: 100.00000  \n",
      "=====> Epoch [34/60], Step [70/140], Loss: 0.11385 , Acc: 99.84375  \n",
      "=====> Epoch [34/60], Step [80/140], Loss: 0.10113 , Acc: 99.68750  \n",
      "=====> Epoch [34/60], Step [90/140], Loss: 0.08825 , Acc: 100.00000  \n",
      "=====> Epoch [34/60], Step [100/140], Loss: 0.08534 , Acc: 100.00000  \n",
      "=====> Epoch [34/60], Step [110/140], Loss: 0.07847 , Acc: 99.84375  \n",
      "=====> Epoch [34/60], Step [120/140], Loss: 0.07820 , Acc: 100.00000  \n",
      "=====> Epoch [34/60], Step [130/140], Loss: 0.09567 , Acc: 100.00000  \n",
      "=====> Epoch [34/60], Step [140/140], Loss: 0.06616 , Acc: 100.00000  \n",
      "===> evaluating models...\n",
      "================\n",
      "val acc: 69.16666666666667 %  epoch: 34\n",
      "================\n",
      "===> Saving models...\n",
      "===> training models...\n",
      "=====> Epoch [35/60], Step [10/140], Loss: 0.08513 , Acc: 99.68750  \n",
      "=====> Epoch [35/60], Step [20/140], Loss: 0.09578 , Acc: 99.84375  \n",
      "=====> Epoch [35/60], Step [30/140], Loss: 0.08237 , Acc: 100.00000  \n",
      "=====> Epoch [35/60], Step [40/140], Loss: 0.05047 , Acc: 100.00000  \n",
      "=====> Epoch [35/60], Step [50/140], Loss: 0.08521 , Acc: 99.84375  \n",
      "=====> Epoch [35/60], Step [60/140], Loss: 0.06253 , Acc: 100.00000  \n",
      "=====> Epoch [35/60], Step [70/140], Loss: 0.10729 , Acc: 100.00000  \n",
      "=====> Epoch [35/60], Step [80/140], Loss: 0.08104 , Acc: 99.84375  \n",
      "=====> Epoch [35/60], Step [90/140], Loss: 0.07841 , Acc: 99.84375  \n",
      "=====> Epoch [35/60], Step [100/140], Loss: 0.07367 , Acc: 100.00000  \n",
      "=====> Epoch [35/60], Step [110/140], Loss: 0.05379 , Acc: 100.00000  \n",
      "=====> Epoch [35/60], Step [120/140], Loss: 0.07875 , Acc: 100.00000  \n",
      "=====> Epoch [35/60], Step [130/140], Loss: 0.09527 , Acc: 99.84375  \n",
      "=====> Epoch [35/60], Step [140/140], Loss: 0.05832 , Acc: 100.00000  \n",
      "===> evaluating models...\n",
      "================\n",
      "val acc: 68.95833333333333 %  epoch: 35\n",
      "================\n",
      "===> training models...\n",
      "=====> Epoch [36/60], Step [10/140], Loss: 0.09574 , Acc: 99.84375  \n",
      "=====> Epoch [36/60], Step [20/140], Loss: 0.09148 , Acc: 99.84375  \n",
      "=====> Epoch [36/60], Step [30/140], Loss: 0.05460 , Acc: 100.00000  \n",
      "=====> Epoch [36/60], Step [40/140], Loss: 0.05750 , Acc: 100.00000  \n",
      "=====> Epoch [36/60], Step [50/140], Loss: 0.08639 , Acc: 99.68750  \n",
      "=====> Epoch [36/60], Step [60/140], Loss: 0.05609 , Acc: 100.00000  \n",
      "=====> Epoch [36/60], Step [70/140], Loss: 0.05651 , Acc: 100.00000  \n",
      "=====> Epoch [36/60], Step [80/140], Loss: 0.05838 , Acc: 100.00000  \n",
      "=====> Epoch [36/60], Step [90/140], Loss: 0.06985 , Acc: 100.00000  \n",
      "=====> Epoch [36/60], Step [100/140], Loss: 0.07153 , Acc: 99.84375  \n",
      "=====> Epoch [36/60], Step [110/140], Loss: 0.07903 , Acc: 100.00000  \n",
      "=====> Epoch [36/60], Step [120/140], Loss: 0.04718 , Acc: 100.00000  \n",
      "=====> Epoch [36/60], Step [130/140], Loss: 0.07665 , Acc: 100.00000  \n",
      "=====> Epoch [36/60], Step [140/140], Loss: 0.07163 , Acc: 99.84375  \n",
      "===> evaluating models...\n",
      "================\n",
      "val acc: 68.4375 %  epoch: 36\n",
      "================\n",
      "===> training models...\n",
      "=====> Epoch [37/60], Step [10/140], Loss: 0.04505 , Acc: 100.00000  \n",
      "=====> Epoch [37/60], Step [20/140], Loss: 0.04105 , Acc: 100.00000  \n",
      "=====> Epoch [37/60], Step [30/140], Loss: 0.06037 , Acc: 100.00000  \n",
      "=====> Epoch [37/60], Step [40/140], Loss: 0.08834 , Acc: 99.68750  \n",
      "=====> Epoch [37/60], Step [50/140], Loss: 0.04602 , Acc: 100.00000  \n",
      "=====> Epoch [37/60], Step [60/140], Loss: 0.13351 , Acc: 99.68750  \n",
      "=====> Epoch [37/60], Step [70/140], Loss: 0.10263 , Acc: 99.84375  \n",
      "=====> Epoch [37/60], Step [80/140], Loss: 0.04936 , Acc: 100.00000  \n",
      "=====> Epoch [37/60], Step [90/140], Loss: 0.08550 , Acc: 99.84375  \n",
      "=====> Epoch [37/60], Step [100/140], Loss: 0.06569 , Acc: 100.00000  \n",
      "=====> Epoch [37/60], Step [110/140], Loss: 0.04754 , Acc: 100.00000  \n",
      "=====> Epoch [37/60], Step [120/140], Loss: 0.06061 , Acc: 100.00000  \n",
      "=====> Epoch [37/60], Step [130/140], Loss: 0.05982 , Acc: 100.00000  \n",
      "=====> Epoch [37/60], Step [140/140], Loss: 0.06208 , Acc: 99.84375  \n",
      "===> evaluating models...\n",
      "================\n",
      "val acc: 68.02083333333333 %  epoch: 37\n",
      "================\n",
      "===> training models...\n",
      "=====> Epoch [38/60], Step [10/140], Loss: 0.04723 , Acc: 100.00000  \n",
      "=====> Epoch [38/60], Step [20/140], Loss: 0.06230 , Acc: 100.00000  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====> Epoch [38/60], Step [30/140], Loss: 0.06061 , Acc: 100.00000  \n",
      "=====> Epoch [38/60], Step [40/140], Loss: 0.05199 , Acc: 100.00000  \n",
      "=====> Epoch [38/60], Step [50/140], Loss: 0.05431 , Acc: 100.00000  \n",
      "=====> Epoch [38/60], Step [60/140], Loss: 0.06441 , Acc: 99.84375  \n",
      "=====> Epoch [38/60], Step [70/140], Loss: 0.05601 , Acc: 99.84375  \n",
      "=====> Epoch [38/60], Step [80/140], Loss: 0.03256 , Acc: 100.00000  \n",
      "=====> Epoch [38/60], Step [90/140], Loss: 0.05427 , Acc: 100.00000  \n",
      "=====> Epoch [38/60], Step [100/140], Loss: 0.12965 , Acc: 99.84375  \n",
      "=====> Epoch [38/60], Step [110/140], Loss: 0.08108 , Acc: 99.84375  \n",
      "=====> Epoch [38/60], Step [120/140], Loss: 0.04541 , Acc: 100.00000  \n",
      "=====> Epoch [38/60], Step [130/140], Loss: 0.06597 , Acc: 100.00000  \n",
      "=====> Epoch [38/60], Step [140/140], Loss: 0.07515 , Acc: 99.68750  \n",
      "===> evaluating models...\n",
      "================\n",
      "val acc: 67.39583333333333 %  epoch: 38\n",
      "================\n",
      "===> training models...\n",
      "=====> Epoch [39/60], Step [10/140], Loss: 0.04470 , Acc: 100.00000  \n",
      "=====> Epoch [39/60], Step [20/140], Loss: 0.04526 , Acc: 100.00000  \n",
      "=====> Epoch [39/60], Step [30/140], Loss: 0.04732 , Acc: 100.00000  \n",
      "=====> Epoch [39/60], Step [40/140], Loss: 0.05024 , Acc: 100.00000  \n",
      "=====> Epoch [39/60], Step [50/140], Loss: 0.04042 , Acc: 100.00000  \n",
      "=====> Epoch [39/60], Step [60/140], Loss: 0.07719 , Acc: 100.00000  \n",
      "=====> Epoch [39/60], Step [70/140], Loss: 0.05225 , Acc: 100.00000  \n",
      "=====> Epoch [39/60], Step [80/140], Loss: 0.07290 , Acc: 100.00000  \n",
      "=====> Epoch [39/60], Step [90/140], Loss: 0.03403 , Acc: 100.00000  \n",
      "=====> Epoch [39/60], Step [100/140], Loss: 0.06832 , Acc: 100.00000  \n",
      "=====> Epoch [39/60], Step [110/140], Loss: 0.04825 , Acc: 100.00000  \n",
      "=====> Epoch [39/60], Step [120/140], Loss: 0.07092 , Acc: 100.00000  \n",
      "=====> Epoch [39/60], Step [130/140], Loss: 0.04352 , Acc: 100.00000  \n",
      "=====> Epoch [39/60], Step [140/140], Loss: 0.04433 , Acc: 100.00000  \n",
      "===> evaluating models...\n",
      "================\n",
      "val acc: 68.22916666666667 %  epoch: 39\n",
      "================\n",
      "===> training models...\n",
      "=====> Epoch [40/60], Step [10/140], Loss: 0.03456 , Acc: 100.00000  \n",
      "=====> Epoch [40/60], Step [20/140], Loss: 0.05624 , Acc: 100.00000  \n",
      "=====> Epoch [40/60], Step [30/140], Loss: 0.04399 , Acc: 100.00000  \n",
      "=====> Epoch [40/60], Step [40/140], Loss: 0.04516 , Acc: 100.00000  \n",
      "=====> Epoch [40/60], Step [50/140], Loss: 0.06385 , Acc: 100.00000  \n",
      "=====> Epoch [40/60], Step [60/140], Loss: 0.06202 , Acc: 99.84375  \n",
      "=====> Epoch [40/60], Step [70/140], Loss: 0.05597 , Acc: 100.00000  \n",
      "=====> Epoch [40/60], Step [80/140], Loss: 0.05004 , Acc: 100.00000  \n",
      "=====> Epoch [40/60], Step [90/140], Loss: 0.06863 , Acc: 99.84375  \n",
      "=====> Epoch [40/60], Step [100/140], Loss: 0.05445 , Acc: 100.00000  \n",
      "=====> Epoch [40/60], Step [110/140], Loss: 0.05552 , Acc: 99.84375  \n",
      "=====> Epoch [40/60], Step [120/140], Loss: 0.05345 , Acc: 99.84375  \n",
      "=====> Epoch [40/60], Step [130/140], Loss: 0.05321 , Acc: 100.00000  \n",
      "=====> Epoch [40/60], Step [140/140], Loss: 0.07304 , Acc: 99.84375  \n",
      "===> evaluating models...\n",
      "================\n",
      "val acc: 68.85416666666667 %  epoch: 40\n",
      "================\n",
      "===> training models...\n",
      "=====> Epoch [41/60], Step [10/140], Loss: 0.04389 , Acc: 100.00000  \n",
      "=====> Epoch [41/60], Step [20/140], Loss: 0.06167 , Acc: 99.84375  \n",
      "=====> Epoch [41/60], Step [30/140], Loss: 0.07639 , Acc: 100.00000  \n",
      "=====> Epoch [41/60], Step [40/140], Loss: 0.03262 , Acc: 100.00000  \n",
      "=====> Epoch [41/60], Step [50/140], Loss: 0.05626 , Acc: 100.00000  \n",
      "=====> Epoch [41/60], Step [60/140], Loss: 0.06015 , Acc: 100.00000  \n",
      "=====> Epoch [41/60], Step [70/140], Loss: 0.03271 , Acc: 100.00000  \n",
      "=====> Epoch [41/60], Step [80/140], Loss: 0.04039 , Acc: 100.00000  \n",
      "=====> Epoch [41/60], Step [90/140], Loss: 0.08813 , Acc: 99.84375  \n",
      "=====> Epoch [41/60], Step [100/140], Loss: 0.06679 , Acc: 99.84375  \n",
      "=====> Epoch [41/60], Step [110/140], Loss: 0.04715 , Acc: 100.00000  \n",
      "=====> Epoch [41/60], Step [120/140], Loss: 0.03871 , Acc: 100.00000  \n",
      "=====> Epoch [41/60], Step [130/140], Loss: 0.04216 , Acc: 100.00000  \n",
      "=====> Epoch [41/60], Step [140/140], Loss: 0.03524 , Acc: 100.00000  \n",
      "===> evaluating models...\n",
      "================\n",
      "val acc: 68.64583333333333 %  epoch: 41\n",
      "================\n",
      "===> training models...\n",
      "=====> Epoch [42/60], Step [10/140], Loss: 0.03778 , Acc: 100.00000  \n",
      "=====> Epoch [42/60], Step [20/140], Loss: 0.04883 , Acc: 100.00000  \n",
      "=====> Epoch [42/60], Step [30/140], Loss: 0.03541 , Acc: 100.00000  \n",
      "=====> Epoch [42/60], Step [40/140], Loss: 0.09252 , Acc: 99.84375  \n",
      "=====> Epoch [42/60], Step [50/140], Loss: 0.03793 , Acc: 100.00000  \n",
      "=====> Epoch [42/60], Step [60/140], Loss: 0.03042 , Acc: 100.00000  \n",
      "=====> Epoch [42/60], Step [70/140], Loss: 0.03594 , Acc: 100.00000  \n",
      "=====> Epoch [42/60], Step [80/140], Loss: 0.04352 , Acc: 100.00000  \n",
      "=====> Epoch [42/60], Step [90/140], Loss: 0.03968 , Acc: 100.00000  \n",
      "=====> Epoch [42/60], Step [100/140], Loss: 0.05160 , Acc: 100.00000  \n",
      "=====> Epoch [42/60], Step [110/140], Loss: 0.04062 , Acc: 100.00000  \n",
      "=====> Epoch [42/60], Step [120/140], Loss: 0.04594 , Acc: 100.00000  \n",
      "=====> Epoch [42/60], Step [130/140], Loss: 0.05188 , Acc: 99.84375  \n",
      "=====> Epoch [42/60], Step [140/140], Loss: 0.04454 , Acc: 100.00000  \n",
      "===> evaluating models...\n",
      "================\n",
      "val acc: 68.02083333333333 %  epoch: 42\n",
      "================\n",
      "===> training models...\n",
      "=====> Epoch [43/60], Step [10/140], Loss: 0.07471 , Acc: 100.00000  \n",
      "=====> Epoch [43/60], Step [20/140], Loss: 0.03666 , Acc: 100.00000  \n",
      "=====> Epoch [43/60], Step [30/140], Loss: 0.05601 , Acc: 99.84375  \n",
      "=====> Epoch [43/60], Step [40/140], Loss: 0.03779 , Acc: 100.00000  \n",
      "=====> Epoch [43/60], Step [50/140], Loss: 0.04325 , Acc: 100.00000  \n",
      "=====> Epoch [43/60], Step [60/140], Loss: 0.03880 , Acc: 100.00000  \n",
      "=====> Epoch [43/60], Step [70/140], Loss: 0.04995 , Acc: 100.00000  \n",
      "=====> Epoch [43/60], Step [80/140], Loss: 0.03806 , Acc: 100.00000  \n",
      "=====> Epoch [43/60], Step [90/140], Loss: 0.05194 , Acc: 99.84375  \n",
      "=====> Epoch [43/60], Step [100/140], Loss: 0.03669 , Acc: 100.00000  \n",
      "=====> Epoch [43/60], Step [110/140], Loss: 0.03765 , Acc: 100.00000  \n",
      "=====> Epoch [43/60], Step [120/140], Loss: 0.04876 , Acc: 100.00000  \n",
      "=====> Epoch [43/60], Step [130/140], Loss: 0.06493 , Acc: 99.84375  \n",
      "=====> Epoch [43/60], Step [140/140], Loss: 0.04951 , Acc: 100.00000  \n",
      "===> evaluating models...\n",
      "================\n",
      "val acc: 68.75 %  epoch: 43\n",
      "================\n",
      "===> training models...\n",
      "=====> Epoch [44/60], Step [10/140], Loss: 0.04163 , Acc: 100.00000  \n",
      "=====> Epoch [44/60], Step [20/140], Loss: 0.03555 , Acc: 100.00000  \n",
      "=====> Epoch [44/60], Step [30/140], Loss: 0.04750 , Acc: 100.00000  \n",
      "=====> Epoch [44/60], Step [40/140], Loss: 0.03397 , Acc: 100.00000  \n",
      "=====> Epoch [44/60], Step [50/140], Loss: 0.06118 , Acc: 100.00000  \n",
      "=====> Epoch [44/60], Step [60/140], Loss: 0.03476 , Acc: 100.00000  \n",
      "=====> Epoch [44/60], Step [70/140], Loss: 0.02823 , Acc: 100.00000  \n",
      "=====> Epoch [44/60], Step [80/140], Loss: 0.03054 , Acc: 100.00000  \n",
      "=====> Epoch [44/60], Step [90/140], Loss: 0.03574 , Acc: 100.00000  \n",
      "=====> Epoch [44/60], Step [100/140], Loss: 0.04248 , Acc: 100.00000  \n",
      "=====> Epoch [44/60], Step [110/140], Loss: 0.05474 , Acc: 100.00000  \n",
      "=====> Epoch [44/60], Step [120/140], Loss: 0.06539 , Acc: 99.84375  \n",
      "=====> Epoch [44/60], Step [130/140], Loss: 0.05573 , Acc: 100.00000  \n",
      "=====> Epoch [44/60], Step [140/140], Loss: 0.06708 , Acc: 100.00000  \n",
      "===> evaluating models...\n",
      "================\n",
      "val acc: 68.85416666666667 %  epoch: 44\n",
      "================\n",
      "===> training models...\n",
      "=====> Epoch [45/60], Step [10/140], Loss: 0.09419 , Acc: 99.84375  \n",
      "=====> Epoch [45/60], Step [20/140], Loss: 0.06407 , Acc: 99.84375  \n",
      "=====> Epoch [45/60], Step [30/140], Loss: 0.03742 , Acc: 100.00000  \n",
      "=====> Epoch [45/60], Step [40/140], Loss: 0.04761 , Acc: 100.00000  \n",
      "=====> Epoch [45/60], Step [50/140], Loss: 0.03006 , Acc: 100.00000  \n",
      "=====> Epoch [45/60], Step [60/140], Loss: 0.04137 , Acc: 100.00000  \n",
      "=====> Epoch [45/60], Step [70/140], Loss: 0.03906 , Acc: 100.00000  \n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from importlib import import_module\n",
    "import torch,time,os,random\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import LIAF\n",
    "from datasets.cifar10_dvs_large import cifar10_DVS\n",
    "from tensorboardX import SummaryWriter\n",
    "from importlib import import_module\n",
    "from LIAFnet.LIAFResNet import *\n",
    "autocast = LIAF.autocast #统一autocast模式\n",
    "\n",
    "################################ parameters ####################\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"1\"\n",
    "for test in range(0,10):\n",
    "    task = 'Large_with_pretarin' + str(test)\n",
    "    writer = SummaryWriter(comment=task)\n",
    "    learning_rate = 1e-3\n",
    "    batch_size  = 64\n",
    "    num_epochs = 100\n",
    "    timeWindows = 8\n",
    "    TA.timeWindows = 8 #用了attention必须固定时间长度\n",
    "    \n",
    "    names = 'dvs_cifar10'\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    train_path = '/data/CIFAR10-MAT' #r := raw string\n",
    "    train_dataset = cifar10_DVS(train_path,'train',timeWindows) #max= 25?\n",
    "    test_dataset = cifar10_DVS(train_path,'test',timeWindows)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                               batch_size=batch_size,\n",
    "                                               shuffle=True)\n",
    "\n",
    "    test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                               batch_size=batch_size,\n",
    "                                               shuffle=False)\n",
    "\n",
    "    TA.timeWindows = 8 #用了attention必须固定时间长度\n",
    "    modules = import_module('LIAFnet.LIAFResNet_18')\n",
    "    config  = modules.Config()\n",
    "    workpath = os.path.abspath(os.getcwd())\n",
    "    num_epochs = 60\n",
    "    accumulation = config.accumulation\n",
    "    timeWindows = config.timeWindows\n",
    "    config.cfgCnn = [2, 64, 7, True]\n",
    "    config.dataSize = (128,128)\n",
    "    config.actFun= LIAF.LIFactFun.apply\n",
    "    epoch = 0\n",
    "    bestacc = 0  # best test accuracy\n",
    "    start_epoch = 0  # start from epoch 0 or last checkpoint epoch\n",
    "    training_iter = 0\n",
    "    snn = LIAFResNet(config)\n",
    "    checkpoint = torch.load('./45.pkl', map_location=torch.device('cpu'))\n",
    "    snn.load_state_dict(checkpoint)\n",
    "    \n",
    "    for p in snn.parameters():\n",
    "        p.requires_grad=False #TODO\n",
    "    snn.fc = nn.Linear(snn.cfgFc_[0],10)\n",
    "    print(\"Total number of paramerters in networks is {}  \".format(sum(x.numel() for x in snn.parameters())))\n",
    "\n",
    "    snn.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    optimizer = torch.optim.Adam(snn.parameters(),\n",
    "                    lr=learning_rate,\n",
    "                    weight_decay =1e-4)\n",
    "\n",
    "\n",
    "    lr_scheduler = torch.optim.lr_scheduler.MultiStepLR(\n",
    "                        optimizer, \n",
    "                        milestones=[30,40,50], \n",
    "                        gamma=0.1, \n",
    "                        last_epoch=-1)\n",
    "    def val(optimizer,snn,test_loader,test_dataset,batch_size,epoch):\n",
    "        print('===> evaluating models...')\n",
    "        snn.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        predicted = 0\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (inputs, labels) in enumerate(test_loader):\n",
    "                if ((batch_idx+1)<=len(test_dataset)//batch_size):\n",
    "                    optimizer.zero_grad()\n",
    "                    outputs = snn(inputs.to(device))\n",
    "                    labels = labels.squeeze(1)\n",
    "                    _ , predicted = outputs.cpu().max(1)\n",
    "                    total += float(labels.size(0))\n",
    "                    correct += float(predicted.eq(labels).sum())\n",
    "        acc = 100. * float(correct) / float(total)\n",
    "        print('================')\n",
    "        print('val acc:',acc , '%  epoch:',epoch)\n",
    "        print('================')\n",
    "        writer.add_scalar('acc', acc, epoch)\n",
    "        return acc\n",
    "\n",
    "    save_folder = './saved_model'\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # 新增2：设置sampler的epoch，DistributedSampler需要这个来维持各个进程之间的相同随机数种子\n",
    "        #train_loader.sampler.set_epoch(epoch)\n",
    "        if epoch>1:\n",
    "            for p in snn.parameters():\n",
    "                p.requires_grad=True #TODO\n",
    "        snn.train()\n",
    "        running_loss = 0\n",
    "        start_time = time.time() \n",
    "        print('===> training models...')\n",
    "        correct = 0.0\n",
    "        total = 0.0\n",
    "        torch.cuda.empty_cache()\n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "            if ((i+1)<=len(train_dataset)//batch_size):\n",
    "                with autocast():\n",
    "                    outputs = snn(images.to(device)).cpu()\n",
    "                    labels = labels.squeeze(1)\n",
    "                    _ , predict = outputs.max(1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    correct += predict.eq(labels).sum()\n",
    "                    total += float(predict.size(0))\n",
    "\n",
    "                    loss /= accumulation\n",
    "                    running_loss += loss.item()\n",
    "                    loss.backward()\n",
    "\n",
    "                if (i+1)%accumulation == 0:\n",
    "                    optimizer.step()\n",
    "                    snn.zero_grad()\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                if (i+1)%(10) == 0:\n",
    "                    if not os.path.isdir(save_folder):\n",
    "                        os.mkdir(save_folder)\n",
    "                    train_acc =  100* correct / total\n",
    "                    print('=====> Epoch [%d/%d], Step [%d/%d], Loss: %.5f , Acc: %.5f  '\n",
    "                      %(epoch+start_epoch, num_epochs+start_epoch, i+1, len(train_dataset)//(batch_size),running_loss, train_acc))\n",
    "                    writer.add_scalar('running Loss', running_loss, training_iter)\n",
    "                    writer.add_scalar('running Acc', train_acc, training_iter)\n",
    "                    correct = 0.0\n",
    "                    total = 0.0\n",
    "                    running_loss = 0\n",
    "                    #\n",
    "            training_iter +=1 \n",
    "        torch.cuda.empty_cache()\n",
    "        #evaluation\n",
    "        acc = val(optimizer,snn,test_loader,test_dataset,batch_size,epoch)\n",
    "        lr_scheduler.step()\n",
    "        if not os.path.isdir(save_folder):\n",
    "            os.mkdir(save_folder)\n",
    "        if acc > bestacc:\n",
    "            bestacc = acc\n",
    "            print('===> Saving models...')\n",
    "\n",
    "\n",
    "    torch.save(snn.state_dict(),'./'+save_folder+'/'+task+str(int(bestacc))+'.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fde7bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "61.197916666666664 %  epoch: 14\n",
    "63.28125 %  epoch: 31"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
