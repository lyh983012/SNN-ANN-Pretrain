{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1bf4c593",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use torch.cuda.amp.autocast for fusion prcision training\n",
      "torch.Size([9000, 2, 42, 42, 8]) torch.Size([9000, 10])\n",
      "torch.Size([1000, 2, 42, 42, 8]) torch.Size([1000, 10])\n",
      "Total number of paramerters in networks is 11185379  \n",
      "===> training models...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lyh/anaconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448255797/work/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====> Epoch [0/40], Step [18/18], Loss: 40.07527 , Acc: 18.34444  \n",
      "===> evaluating models...\n",
      "================\n",
      "val acc: 11.3 %  epoch: 0\n",
      "================\n",
      "===> Saving models...\n",
      "===> training models...\n",
      "=====> Epoch [1/40], Step [18/18], Loss: 37.65362 , Acc: 25.38889  \n",
      "===> evaluating models...\n",
      "================\n",
      "val acc: 24.7 %  epoch: 1\n",
      "================\n",
      "===> Saving models...\n",
      "===> training models...\n",
      "=====> Epoch [2/40], Step [18/18], Loss: 35.04057 , Acc: 29.63333  \n",
      "===> evaluating models...\n",
      "================\n",
      "val acc: 11.3 %  epoch: 2\n",
      "================\n",
      "===> training models...\n",
      "=====> Epoch [3/40], Step [18/18], Loss: 29.68761 , Acc: 40.14444  \n",
      "===> evaluating models...\n",
      "================\n",
      "val acc: 20.1 %  epoch: 3\n",
      "================\n",
      "===> training models...\n",
      "=====> Epoch [4/40], Step [18/18], Loss: 28.58351 , Acc: 43.90000  \n",
      "===> evaluating models...\n",
      "================\n",
      "val acc: 15.4 %  epoch: 4\n",
      "================\n",
      "===> training models...\n",
      "=====> Epoch [5/40], Step [18/18], Loss: 28.15687 , Acc: 43.65556  \n",
      "===> evaluating models...\n",
      "================\n",
      "val acc: 15.3 %  epoch: 5\n",
      "================\n",
      "===> training models...\n",
      "=====> Epoch [6/40], Step [18/18], Loss: 27.58492 , Acc: 45.12222  \n",
      "===> evaluating models...\n",
      "================\n",
      "val acc: 10.2 %  epoch: 6\n",
      "================\n",
      "===> training models...\n",
      "=====> Epoch [7/40], Step [18/18], Loss: 26.24489 , Acc: 47.65556  \n",
      "===> evaluating models...\n",
      "================\n",
      "val acc: 14.8 %  epoch: 7\n",
      "================\n",
      "===> training models...\n",
      "=====> Epoch [8/40], Step [18/18], Loss: 25.67002 , Acc: 49.76667  \n",
      "===> evaluating models...\n",
      "================\n",
      "val acc: 13.7 %  epoch: 8\n",
      "================\n",
      "===> training models...\n",
      "=====> Epoch [9/40], Step [18/18], Loss: 25.27516 , Acc: 49.51111  \n",
      "===> evaluating models...\n",
      "================\n",
      "val acc: 14.6 %  epoch: 9\n",
      "================\n",
      "===> training models...\n",
      "=====> Epoch [10/40], Step [18/18], Loss: 24.38097 , Acc: 52.00000  \n",
      "===> evaluating models...\n",
      "================\n",
      "val acc: 10.7 %  epoch: 10\n",
      "================\n",
      "===> training models...\n",
      "=====> Epoch [11/40], Step [18/18], Loss: 23.79960 , Acc: 52.83333  \n",
      "===> evaluating models...\n",
      "================\n",
      "val acc: 12.8 %  epoch: 11\n",
      "================\n",
      "===> training models...\n",
      "=====> Epoch [12/40], Step [18/18], Loss: 23.36089 , Acc: 54.07778  \n",
      "===> evaluating models...\n",
      "================\n",
      "val acc: 13.8 %  epoch: 12\n",
      "================\n",
      "===> training models...\n",
      "=====> Epoch [13/40], Step [18/18], Loss: 23.12264 , Acc: 55.08889  \n",
      "===> evaluating models...\n",
      "================\n",
      "val acc: 20.9 %  epoch: 13\n",
      "================\n",
      "===> training models...\n",
      "=====> Epoch [14/40], Step [18/18], Loss: 22.92627 , Acc: 54.92222  \n",
      "===> evaluating models...\n",
      "================\n",
      "val acc: 15.8 %  epoch: 14\n",
      "================\n",
      "===> training models...\n",
      "=====> Epoch [15/40], Step [18/18], Loss: 22.26409 , Acc: 56.02222  \n",
      "===> evaluating models...\n",
      "================\n",
      "val acc: 19.9 %  epoch: 15\n",
      "================\n",
      "===> training models...\n",
      "=====> Epoch [16/40], Step [18/18], Loss: 21.56092 , Acc: 57.52222  \n",
      "===> evaluating models...\n",
      "================\n",
      "val acc: 27.9 %  epoch: 16\n",
      "================\n",
      "===> Saving models...\n",
      "===> training models...\n",
      "=====> Epoch [17/40], Step [18/18], Loss: 21.44281 , Acc: 57.98889  \n",
      "===> evaluating models...\n",
      "================\n",
      "val acc: 14.2 %  epoch: 17\n",
      "================\n",
      "===> training models...\n",
      "=====> Epoch [18/40], Step [18/18], Loss: 20.89181 , Acc: 59.54445  \n",
      "===> evaluating models...\n",
      "================\n",
      "val acc: 26.0 %  epoch: 18\n",
      "================\n",
      "===> training models...\n",
      "=====> Epoch [19/40], Step [18/18], Loss: 20.36154 , Acc: 59.94444  \n",
      "===> evaluating models...\n",
      "================\n",
      "val acc: 10.7 %  epoch: 19\n",
      "================\n",
      "===> training models...\n",
      "=====> Epoch [20/40], Step [18/18], Loss: 17.70688 , Acc: 66.00000  \n",
      "===> evaluating models...\n",
      "================\n",
      "val acc: 50.5 %  epoch: 20\n",
      "================\n",
      "===> Saving models...\n",
      "===> training models...\n",
      "=====> Epoch [21/40], Step [18/18], Loss: 15.52939 , Acc: 70.30000  \n",
      "===> evaluating models...\n",
      "================\n",
      "val acc: 52.6 %  epoch: 21\n",
      "================\n",
      "===> Saving models...\n",
      "===> training models...\n",
      "=====> Epoch [22/40], Step [18/18], Loss: 14.29096 , Acc: 73.10000  \n",
      "===> evaluating models...\n",
      "================\n",
      "val acc: 52.5 %  epoch: 22\n",
      "================\n",
      "===> training models...\n",
      "=====> Epoch [23/40], Step [18/18], Loss: 13.31398 , Acc: 74.54444  \n",
      "===> evaluating models...\n",
      "================\n",
      "val acc: 54.6 %  epoch: 23\n",
      "================\n",
      "===> Saving models...\n",
      "===> training models...\n",
      "=====> Epoch [24/40], Step [18/18], Loss: 12.51187 , Acc: 76.18889  \n",
      "===> evaluating models...\n",
      "================\n",
      "val acc: 55.4 %  epoch: 24\n",
      "================\n",
      "===> Saving models...\n",
      "===> training models...\n",
      "=====> Epoch [25/40], Step [18/18], Loss: 11.54643 , Acc: 78.51111  \n",
      "===> evaluating models...\n",
      "================\n",
      "val acc: 56.3 %  epoch: 25\n",
      "================\n",
      "===> Saving models...\n",
      "===> training models...\n",
      "=====> Epoch [26/40], Step [18/18], Loss: 10.58408 , Acc: 80.26667  \n",
      "===> evaluating models...\n",
      "================\n",
      "val acc: 52.9 %  epoch: 26\n",
      "================\n",
      "===> training models...\n",
      "=====> Epoch [27/40], Step [18/18], Loss: 9.58694 , Acc: 82.38889  \n",
      "===> evaluating models...\n",
      "================\n",
      "val acc: 55.0 %  epoch: 27\n",
      "================\n",
      "===> training models...\n",
      "=====> Epoch [28/40], Step [18/18], Loss: 8.56334 , Acc: 84.57777  \n",
      "===> evaluating models...\n",
      "================\n",
      "val acc: 47.2 %  epoch: 28\n",
      "================\n",
      "===> training models...\n",
      "=====> Epoch [29/40], Step [18/18], Loss: 7.43627 , Acc: 87.10000  \n",
      "===> evaluating models...\n",
      "================\n",
      "val acc: 57.7 %  epoch: 29\n",
      "================\n",
      "===> Saving models...\n",
      "===> training models...\n",
      "=====> Epoch [30/40], Step [18/18], Loss: 6.50365 , Acc: 88.66666  \n",
      "===> evaluating models...\n",
      "================\n",
      "val acc: 42.6 %  epoch: 30\n",
      "================\n",
      "===> training models...\n",
      "=====> Epoch [31/40], Step [18/18], Loss: 5.64324 , Acc: 90.42223  \n",
      "===> evaluating models...\n",
      "================\n",
      "val acc: 55.8 %  epoch: 31\n",
      "================\n",
      "===> training models...\n",
      "=====> Epoch [32/40], Step [18/18], Loss: 4.91783 , Acc: 91.71111  \n",
      "===> evaluating models...\n",
      "================\n",
      "val acc: 54.3 %  epoch: 32\n",
      "================\n",
      "===> training models...\n",
      "=====> Epoch [33/40], Step [18/18], Loss: 4.58421 , Acc: 92.27778  \n",
      "===> evaluating models...\n",
      "================\n",
      "val acc: 46.8 %  epoch: 33\n",
      "================\n",
      "===> training models...\n",
      "=====> Epoch [34/40], Step [18/18], Loss: 4.42093 , Acc: 92.23333  \n",
      "===> evaluating models...\n",
      "================\n",
      "val acc: 45.7 %  epoch: 34\n",
      "================\n",
      "===> training models...\n",
      "=====> Epoch [35/40], Step [18/18], Loss: 3.91143 , Acc: 93.31111  \n",
      "===> evaluating models...\n",
      "================\n",
      "val acc: 48.5 %  epoch: 35\n",
      "================\n",
      "===> training models...\n",
      "=====> Epoch [36/40], Step [18/18], Loss: 3.41128 , Acc: 94.35555  \n",
      "===> evaluating models...\n",
      "================\n",
      "val acc: 41.9 %  epoch: 36\n",
      "================\n",
      "===> training models...\n",
      "=====> Epoch [37/40], Step [18/18], Loss: 3.20559 , Acc: 94.75555  \n",
      "===> evaluating models...\n",
      "================\n",
      "val acc: 48.1 %  epoch: 37\n",
      "================\n",
      "===> training models...\n",
      "=====> Epoch [38/40], Step [18/18], Loss: 2.85753 , Acc: 95.46667  \n",
      "===> evaluating models...\n",
      "================\n",
      "val acc: 41.5 %  epoch: 38\n",
      "================\n",
      "===> training models...\n",
      "=====> Epoch [39/40], Step [18/18], Loss: 2.48425 , Acc: 96.20000  \n",
      "===> evaluating models...\n",
      "================\n",
      "val acc: 45.9 %  epoch: 39\n",
      "================\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# python3 example_cifar10_scnn.py\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from importlib import import_module\n",
    "import torch,time,os,random\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import LIAF\n",
    "from datasets.cifar10_dvs_simple import cifar10_DVS\n",
    "from tensorboardX import SummaryWriter\n",
    "from importlib import import_module\n",
    "from LIAFnet.LIAFResNet import *\n",
    "autocast = LIAF.autocast #统一autocast模式\n",
    "\n",
    "################################ parameters ####################\n",
    "\n",
    "for test in range(1):\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = \"1\"\n",
    "    task = '32ESpretrain' + str(test)\n",
    "    writer = SummaryWriter(comment=task)\n",
    "    learning_rate = 3e-3\n",
    "    batch_size  = 500\n",
    "    num_epochs = 100\n",
    "    timeWindows = 8\n",
    "    names = 'dvs_cifar10'\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    train_path = '/data/CIFAR10-DVS-mini/train.mat' #r := raw string\n",
    "    test_path =  '/data/CIFAR10-DVS-mini/test.mat' #TODO:input your oath\n",
    "\n",
    "    train_dataset = cifar10_DVS(train_path,'r',timeWindows) #max= 25?\n",
    "    test_dataset = cifar10_DVS(test_path,'r',timeWindows)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                               batch_size=batch_size,\n",
    "                                               shuffle=True)\n",
    "\n",
    "    test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                               batch_size=batch_size,\n",
    "                                               shuffle=False)\n",
    "\n",
    "    TA.timeWindows = 8 #用了attention必须固定时间长度\n",
    "    modules = import_module('LIAFnet.LIAFResNet_18')\n",
    "    config  = modules.Config()\n",
    "    workpath = os.path.abspath(os.getcwd())\n",
    "    num_epochs = config.num_epochs\n",
    "    accumulation = config.accumulation\n",
    "    timeWindows = config.timeWindows\n",
    "    config.cfgCnn = [2, 64, 7, True]\n",
    "    config.dataSize = (42,42)\n",
    "    config.actFun= LIAF.LIFactFun.apply\n",
    "    epoch = 0\n",
    "    bestacc = 0  # best test accuracy\n",
    "    start_epoch = 0  # start from epoch 0 or last checkpoint epoch\n",
    "    training_iter = 0\n",
    "    snn = LIAFResNet(config)\n",
    "    checkpoint = torch.load('./45.pkl', map_location=torch.device('cpu'))\n",
    "    snn.load_state_dict(checkpoint)\n",
    "    for p in snn.parameters():\n",
    "        p.requires_grad=False #TODO\n",
    "    snn.fc = nn.Linear(snn.cfgFc_[0],10)\n",
    "    print(\"Total number of paramerters in networks is {}  \".format(sum(x.numel() for x in snn.parameters())))\n",
    "\n",
    "    snn.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    optimizer = torch.optim.Adam(snn.parameters(),\n",
    "                    lr=learning_rate,\n",
    "                    weight_decay =1e-4)\n",
    "\n",
    "\n",
    "    lr_scheduler = torch.optim.lr_scheduler.MultiStepLR(\n",
    "                        optimizer, \n",
    "                        milestones=[20,40,60], \n",
    "                        gamma=0.1, \n",
    "                        last_epoch=-1)\n",
    "    def val(optimizer,snn,test_loader,test_dataset,batch_size,epoch):\n",
    "        print('===> evaluating models...')\n",
    "        snn.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        predicted = 0\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (inputs, labels) in enumerate(test_loader):\n",
    "                inputs = inputs.permute([0,1,4,2,3])\n",
    "                if ((batch_idx+1)<=len(test_dataset)//batch_size):\n",
    "                    optimizer.zero_grad()\n",
    "                    outputs = snn(inputs.to(device))\n",
    "\n",
    "                    _ , labels = labels.max(1)\n",
    "                    _ , predicted = outputs.cpu().max(1)\n",
    "                    total += float(labels.size(0))\n",
    "                    correct += float(predicted.eq(labels).sum())\n",
    "        acc = 100. * float(correct) / float(total)\n",
    "        print('================')\n",
    "        print('val acc:',acc , '%  epoch:',epoch)\n",
    "        print('================')\n",
    "        writer.add_scalar('acc', acc, epoch)\n",
    "        return acc\n",
    "\n",
    "    save_folder = './saved_model'\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # 新增2：设置sampler的epoch，DistributedSampler需要这个来维持各个进程之间的相同随机数种子\n",
    "        if epoch>1:\n",
    "            for p in snn.parameters():\n",
    "                p.requires_grad=True #TODO\n",
    "        snn.train()\n",
    "        running_loss = 0\n",
    "        start_time = time.time() \n",
    "        print('===> training models...')\n",
    "        correct = 0.0\n",
    "        total = 0.0\n",
    "        torch.cuda.empty_cache()\n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "            images = images.permute([0,1,4,2,3])\n",
    "            if ((i+1)<=len(train_dataset)//batch_size):\n",
    "                with autocast():\n",
    "                    outputs = snn(images.to(device)).cpu()\n",
    "                    _,labels = labels.max(1)\n",
    "                    _ , predict = outputs.max(1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    correct += predict.eq(labels).sum()\n",
    "                    total += float(predict.size(0))\n",
    "\n",
    "                    loss /= accumulation\n",
    "                    running_loss += loss.item()\n",
    "                    loss.backward()\n",
    "\n",
    "                if (i+1)%accumulation == 0:\n",
    "                    optimizer.step()\n",
    "                    snn.zero_grad()\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                if (i+1)%(accumulation*18) == 0:\n",
    "                    if not os.path.isdir(save_folder):\n",
    "                        os.mkdir(save_folder)\n",
    "                    train_acc =  100* correct / total\n",
    "                    print('=====> Epoch [%d/%d], Step [%d/%d], Loss: %.5f , Acc: %.5f  '\n",
    "                      %(epoch+start_epoch, num_epochs+start_epoch, i+1, len(train_dataset)//(batch_size),running_loss, train_acc))\n",
    "                    writer.add_scalar('running Loss', running_loss, training_iter)\n",
    "                    writer.add_scalar('running Acc', train_acc, training_iter)\n",
    "                    correct = 0.0\n",
    "                    total = 0.0\n",
    "                    running_loss = 0\n",
    "            training_iter +=1 \n",
    "        torch.cuda.empty_cache()\n",
    "        #evaluation\n",
    "        acc = val(optimizer,snn,test_loader,test_dataset,batch_size,epoch)\n",
    "        lr_scheduler.step()\n",
    "        if not os.path.isdir(save_folder):\n",
    "            os.mkdir(save_folder)\n",
    "        if acc > bestacc:\n",
    "            bestacc = acc\n",
    "            print('===> Saving models...')\n",
    "\n",
    "\n",
    "    torch.save(snn.state_dict(),'./'+save_folder+'/'+task+str(int(bestacc))+'.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
